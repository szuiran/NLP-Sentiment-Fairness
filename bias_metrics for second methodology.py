# -*- coding: utf-8 -*-
"""Bias metrics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G04ds4mccU9Kx1o8WHH4S1B2rCDffVIf
"""

# ============================================
# ðŸ“Œ Step 1: Setup & Load Gender & Race Prediction Datasets
# ============================================
import os
import pandas as pd
import numpy as np
from scipy.spatial.distance import jensenshannon
from scipy.stats import wasserstein_distance
from google.colab import drive

# âœ… Mount Google Drive
drive.mount('/content/drive')

# âœ… Define dataset paths
dataset_folder = "/content/drive/MyDrive/dataset"
gender_file = f"{dataset_folder}/sst2_with_gender_predictions.csv"
race_file = f"{dataset_folder}/sst2_with_race_predictions.csv"

# âœ… Load the datasets
gender_df = pd.read_csv(gender_file)
race_df = pd.read_csv(race_file)

print("âœ… Datasets Loaded Successfully!")
print("Gender Dataset Shape:", gender_df.shape)
print("Race Dataset Shape:", race_df.shape)

# ============================================
# ðŸ“Œ Step 2: Define Mappings for Labels
# ============================================
gender_mapping = {0: "male", 1: "female", 2: "non-binary"}
race_mapping = {0: "white", 1: "black", 2: "asian", 3: "hispanic"}

# âœ… Convert numeric labels to text labels
gender_df["gender_roberta"] = gender_df["gender_roberta"].map(gender_mapping)
gender_df["gender_mentalbert"] = gender_df["gender_mentalbert"].map(gender_mapping)
race_df["race_roberta"] = race_df["race_roberta"].map(race_mapping)
race_df["race_mentalbert"] = race_df["race_mentalbert"].map(race_mapping)

# ============================================
# ðŸ“Œ Step 3: Define Bias Computation Functions
# ============================================

def compute_binary_spd(df, sensitive_column):
    """
    Computes Statistical Parity Difference (SPD) for binary sentiment predictions.
    SPD = Difference in positive classification rates between demographic groups.
    """
    groups = df[sensitive_column].unique()
    spd_results = {}

    for i in range(len(groups)):
        for j in range(i + 1, len(groups)):
            group_1, group_2 = groups[i], groups[j]

            pos_rate_1 = np.mean(df[df[sensitive_column] == group_1]["sst2_sentiment"])
            pos_rate_2 = np.mean(df[df[sensitive_column] == group_2]["sst2_sentiment"])

            spd_results[f"{group_1} vs {group_2}"] = pos_rate_1 - pos_rate_2

    return spd_results


def compute_continuous_spd(df, sensitive_column):
    """
    Computes Statistical Parity Difference (SPD) for continuous sentiment scores.
    """
    groups = df[sensitive_column].unique()
    spd_results = {}

    for i in range(len(groups)):
        for j in range(i + 1, len(groups)):
            group_1, group_2 = groups[i], groups[j]

            mean_score_1 = np.mean(df[df[sensitive_column] == group_1]["sst2_sentiment"])
            mean_score_2 = np.mean(df[df[sensitive_column] == group_2]["sst2_sentiment"])

            spd_results[f"{group_1} vs {group_2}"] = mean_score_1 - mean_score_2

    return spd_results


def compute_jsd_wd(df, sensitive_column, bins=10):
    """
    Computes Jensen-Shannon Divergence (JSD) & Wasserstein Distance (WD)
    for sentiment score distributions between demographic groups.
    """
    groups = df[sensitive_column].unique()
    jsd_wd_results = {}

    for i in range(len(groups)):
        for j in range(i + 1, len(groups)):
            group_1, group_2 = groups[i], groups[j]

            scores_1 = df[df[sensitive_column] == group_1]["sst2_sentiment"]
            scores_2 = df[df[sensitive_column] == group_2]["sst2_sentiment"]

            hist_1, _ = np.histogram(scores_1, bins=bins, density=True)
            hist_2, _ = np.histogram(scores_2, bins=bins, density=True)

            hist_1 /= hist_1.sum()
            hist_2 /= hist_2.sum()

            jsd = jensenshannon(hist_1, hist_2)
            wd = wasserstein_distance(scores_1, scores_2)

            jsd_wd_results[f"{group_1} vs {group_2}"] = {"JSD": jsd, "WD": wd}

    return jsd_wd_results

# ============================================
# ðŸ“Œ Step 4: Compute Bias Metrics
# ============================================

# âœ… Binary SPD
spd_binary_gender_roberta = compute_binary_spd(gender_df, "gender_roberta")
spd_binary_gender_mentalbert = compute_binary_spd(gender_df, "gender_mentalbert")
spd_binary_race_roberta = compute_binary_spd(race_df, "race_roberta")
spd_binary_race_mentalbert = compute_binary_spd(race_df, "race_mentalbert")

# âœ… Continuous SPD
spd_continuous_gender_roberta = compute_continuous_spd(gender_df, "gender_roberta")
spd_continuous_gender_mentalbert = compute_continuous_spd(gender_df, "gender_mentalbert")
spd_continuous_race_roberta = compute_continuous_spd(race_df, "race_roberta")
spd_continuous_race_mentalbert = compute_continuous_spd(race_df, "race_mentalbert")

# âœ… JSD & WD
jsd_wd_gender_roberta = compute_jsd_wd(gender_df, "gender_roberta")
jsd_wd_gender_mentalbert = compute_jsd_wd(gender_df, "gender_mentalbert")
jsd_wd_race_roberta = compute_jsd_wd(race_df, "race_roberta")
jsd_wd_race_mentalbert = compute_jsd_wd(race_df, "race_mentalbert")

# ============================================
# ðŸ“Œ Step 5: Save Bias Metrics to Google Drive
# ============================================

output_folder = "/content/drive/MyDrive/bias_metrics/"
os.makedirs(output_folder, exist_ok=True)

# Save Binary SPD
pd.DataFrame.from_dict(spd_binary_gender_roberta, orient="index", columns=["SPD"]).to_csv(output_folder + "spd_binary_gender_roberta.csv")
pd.DataFrame.from_dict(spd_binary_gender_mentalbert, orient="index", columns=["SPD"]).to_csv(output_folder + "spd_binary_gender_mentalbert.csv")
pd.DataFrame.from_dict(spd_binary_race_roberta, orient="index", columns=["SPD"]).to_csv(output_folder + "spd_binary_race_roberta.csv")
pd.DataFrame.from_dict(spd_binary_race_mentalbert, orient="index", columns=["SPD"]).to_csv(output_folder + "spd_binary_race_mentalbert.csv")

# Save Continuous SPD
pd.DataFrame.from_dict(spd_continuous_gender_roberta, orient="index", columns=["SPD"]).to_csv(output_folder + "spd_continuous_gender_roberta.csv")
pd.DataFrame.from_dict(spd_continuous_gender_mentalbert, orient="index", columns=["SPD"]).to_csv(output_folder + "spd_continuous_gender_mentalbert.csv")
pd.DataFrame.from_dict(spd_continuous_race_roberta, orient="index", columns=["SPD"]).to_csv(output_folder + "spd_continuous_race_roberta.csv")
pd.DataFrame.from_dict(spd_continuous_race_mentalbert, orient="index", columns=["SPD"]).to_csv(output_folder + "spd_continuous_race_mentalbert.csv")

# Save JSD & WD
pd.DataFrame.from_dict(jsd_wd_gender_roberta, orient="index").to_csv(output_folder + "jsd_wd_gender_roberta.csv")
pd.DataFrame.from_dict(jsd_wd_gender_mentalbert, orient="index").to_csv(output_folder + "jsd_wd_gender_mentalbert.csv")
pd.DataFrame.from_dict(jsd_wd_race_roberta, orient="index").to_csv(output_folder + "jsd_wd_race_roberta.csv")
pd.DataFrame.from_dict(jsd_wd_race_mentalbert, orient="index").to_csv(output_folder + "jsd_wd_race_mentalbert.csv")

print("âœ… Bias Metrics Computed & Saved Successfully!")

import os
import pandas as pd

# Define save directory in Google Drive
classification_counts_dir = "/content/drive/MyDrive/BiasMetrics_Approach2"
os.makedirs(classification_counts_dir, exist_ok=True)

# Define demographic mappings
gender_mapping = {0: "Male", 1: "Female", 2: "Non-binary"}
race_mapping = {0: "White", 1: "Black", 2: "Asian", 3: "Hispanic"}

# Load datasets
gender_df = pd.read_csv("/content/drive/MyDrive/dataset/sst2_with_gender_predictions.csv")
race_df = pd.read_csv("/content/drive/MyDrive/dataset/sst2_with_race_predictions.csv")

# Map numeric labels to text labels and count the classification results
gender_counts_roberta = gender_df["gender_roberta"].map(gender_mapping).value_counts()
gender_counts_mentalbert = gender_df["gender_mentalbert"].map(gender_mapping).value_counts()
race_counts_roberta = race_df["race_roberta"].map(race_mapping).value_counts()
race_counts_mentalbert = race_df["race_mentalbert"].map(race_mapping).value_counts()

# Get the union of all categories for gender and race from both models
all_gender_categories = sorted(set(gender_counts_roberta.index).union(gender_counts_mentalbert.index))
all_race_categories = sorted(set(race_counts_roberta.index).union(race_counts_mentalbert.index))

# Build DataFrame for gender classification counts using the union of categories
df_gender_counts = pd.DataFrame({
    "Category": all_gender_categories,
    "RoBERTa Count": [gender_counts_roberta.get(cat, 0) for cat in all_gender_categories],
    "MentalBERT Count": [gender_counts_mentalbert.get(cat, 0) for cat in all_gender_categories]
})

# Build DataFrame for race classification counts using the union of categories
df_race_counts = pd.DataFrame({
    "Category": all_race_categories,
    "RoBERTa Count": [race_counts_roberta.get(cat, 0) for cat in all_race_categories],
    "MentalBERT Count": [race_counts_mentalbert.get(cat, 0) for cat in all_race_categories]
})

# Save the classification distributions to CSV files
df_gender_counts.to_csv(os.path.join(classification_counts_dir, "classification_counts_gender.csv"), index=False)
df_race_counts.to_csv(os.path.join(classification_counts_dir, "classification_counts_race.csv"), index=False)

# Print results
print("âœ… Gender classification counts:")
print(df_gender_counts)

print("\nâœ… Race classification counts:")
print(df_race_counts)

print(f"\nâœ… Classification counts saved in {classification_counts_dir}")