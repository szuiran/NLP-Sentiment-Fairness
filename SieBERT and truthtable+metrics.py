# -*- coding: utf-8 -*-
"""TruthTable+Metrics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JKWS09QG0IxQiRtq7vYlyXLZtVPgNi4t
"""

# ============================================

# Section 1: Environment Setup & Loading CALM Dataset
# ============================================
!mkdir -p CALM/data/gender_datasets CALM/data/race_datasets

# Download Gender Dataset
!wget -O CALM/data/gender_datasets/sentiment_gender_dataset.jsonl "https://huggingface.co/datasets/vipulgupta/CALM/raw/main/data/gender_datasets/sentiment_gender_dataset.jsonl"

# Download Race Dataset
!wget -O CALM/data/race_datasets/sentiment_race_dataset.jsonl "https://huggingface.co/datasets/vipulgupta/CALM/raw/main/data/race_datasets/sentiment_race_dataset.jsonl"

import os
import json
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from torch.utils.data import DataLoader, TensorDataset
import numpy as np

print("Gender dataset exists:", os.path.exists("CALM/data/gender_datasets/sentiment_gender_dataset.jsonl"))
print("Race dataset exists:", os.path.exists("CALM/data/race_datasets/sentiment_race_dataset.jsonl"))

# Mount Google Drive to save outputs
from google.colab import drive
drive.mount('/content/drive')

# Load Gender and Race datasets into DataFrames
gender_data_path = "CALM/data/gender_datasets/sentiment_gender_dataset.jsonl"
race_data_path   = "CALM/data/race_datasets/sentiment_race_dataset.jsonl"

with open(gender_data_path, "r", encoding="utf-8") as f:
    gender_data = [json.loads(line) for line in f]
df_calm_gender = pd.DataFrame(gender_data)[["sentence","gender"]].rename(columns={"sentence": "text"})

with open(race_data_path, "r", encoding="utf-8") as f:
    race_data = [json.loads(line) for line in f]
df_calm_race = pd.DataFrame(race_data)[["sentence","race"]].rename(columns={"sentence": "text"})

print("\n CALM datasets loaded!")

# ============================================
# Section 2: Generate Truth Table using Siebert's RoBERTa
# ============================================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("\n Using device:", device)

# Load Siebert's Sentiment Model
truth_model_name = "siebert/sentiment-roberta-large-english"
truth_tokenizer = AutoTokenizer.from_pretrained(truth_model_name)
truth_model = AutoModelForSequenceClassification.from_pretrained(truth_model_name).to(device)

print("\n Loading Siebert's Sentiment Model...")

def tokenize_sentences(df, tokenizer, max_length=128):
    return tokenizer(
        df["text"].tolist(),
        padding=True,
        truncation=True,
        max_length=max_length,
        return_tensors="pt"
    )

def predict_truth_labels(model, inputs, batch_size=32):
    dataset = TensorDataset(inputs["input_ids"], inputs["attention_mask"])
    dataloader = DataLoader(dataset, batch_size=batch_size)

    all_labels = []
    model.eval()
    with torch.no_grad():
        for batch in dataloader:
            input_ids, attention_mask = [b.to(device) for b in batch]
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            preds = torch.argmax(logits, dim=1).cpu().numpy()
            all_labels.extend(preds)
    return np.array(all_labels)

# Create directory for saving truth table
truth_table_folder = "/content/drive/MyDrive/CALMtruthtable"
os.makedirs(truth_table_folder, exist_ok=True)

# Apply to Gender Dataset
gender_inputs = tokenize_sentences(df_calm_gender, truth_tokenizer)
df_calm_gender["truth_label"] = predict_truth_labels(truth_model, gender_inputs)
df_calm_gender.to_csv(os.path.join(truth_table_folder, "calm_truth_table_gender.csv"), index=False)

# Apply to Race Dataset
race_inputs = tokenize_sentences(df_calm_race, truth_tokenizer)
df_calm_race["truth_label"] = predict_truth_labels(truth_model, race_inputs)
df_calm_race.to_csv(os.path.join(truth_table_folder, "calm_truth_table_race.csv"), index=False)

print(" Truth Table Generated & Saved!")

# ============================================
# Section 3: Compute Bias Metrics (EOD, TPR, FPR, FNR) in 3 Ways
# ============================================

# Define the bias metric functions
def compute_eod(df, model_label_col, truth_label_col):
    positive_truth = df[df[truth_label_col] == 1]
    return positive_truth[model_label_col].mean()

def compute_fpr(df, model_label_col, truth_label_col):
    false_positive = df[(df[truth_label_col] == 0) & (df[model_label_col] == 1)]
    return len(false_positive) / len(df[df[truth_label_col] == 0]) if len(df[df[truth_label_col] == 0]) > 0 else 0

def compute_fnr(df, model_label_col, truth_label_col):
    false_negative = df[(df[truth_label_col] == 1) & (df[model_label_col] == 0)]
    return len(false_negative) / len(df[df[truth_label_col] == 1]) if len(df[df[truth_label_col] == 1]) > 0 else 0

def compute_group_vs_rest(df, metric_fn, model_label_col, truth_label_col, group_col):
    return df.groupby(group_col).apply(lambda x: metric_fn(x, model_label_col, truth_label_col)) - metric_fn(df, model_label_col, truth_label_col)

def compute_pairwise(df, metric_fn, model_label_col, truth_label_col, group_col):
    unique_groups = df[group_col].unique()
    results = []
    for g1 in unique_groups:
        for g2 in unique_groups:
            if g1 != g2:
                diff = metric_fn(df[df[group_col] == g1], model_label_col, truth_label_col) - metric_fn(df[df[group_col] == g2], model_label_col, truth_label_col)
                results.append((g1, g2, abs(diff)))
    return pd.DataFrame(results, columns=["Group1", "Group2", "Difference"])

def compute_max_min(df, metric_fn, model_label_col, truth_label_col, group_col):
    group_metrics = df.groupby(group_col).apply(lambda x: metric_fn(x, model_label_col, truth_label_col))
    return group_metrics.max() - group_metrics.min()

# Load model predictions
gender_predictions = pd.read_csv("/content/drive/MyDrive/CALMdatasets/gender_predictions.csv")
race_predictions = pd.read_csv("/content/drive/MyDrive/CALMdatasets/race_predictions.csv")

gender_truth = pd.read_csv(os.path.join(truth_table_folder, "calm_truth_table_gender.csv"))
race_truth = pd.read_csv(os.path.join(truth_table_folder, "calm_truth_table_race.csv"))
#normalize text column
gender_predictions["text"] = gender_predictions["text"].str.lower().str.strip()
gender_truth["text"] = gender_truth["text"].str.lower().str.strip()

race_predictions["text"] = race_predictions["text"].str.lower().str.strip()
race_truth["text"] = race_truth["text"].str.lower().str.strip()


# Merge Truth Labels
gender_eval = gender_predictions.merge(gender_truth[["text", "truth_label"]], on="text")
race_eval = race_predictions.merge(race_truth[["text", "truth_label"]], on="text")

# Compute Metrics
bias_metrics_folder = "/content/drive/MyDrive/CALMresults/truthtable_bias_metrics"
os.makedirs(bias_metrics_folder, exist_ok=True)

for metric_name, metric_fn in zip(["EOD", "FPR", "FNR"], [compute_eod, compute_fpr, compute_fnr]):
    for dataset_name, df, group_col in zip(["gender", "race"], [gender_eval, race_eval], ["gender", "race"]):
        group_vs_rest = compute_group_vs_rest(df, metric_fn, "roberta_label", "truth_label", group_col)
        pairwise = compute_pairwise(df, metric_fn, "roberta_label", "truth_label", group_col)
        max_min = compute_max_min(df, metric_fn, "roberta_label", "truth_label", group_col)

        group_vs_rest.to_csv(os.path.join(bias_metrics_folder, f"{metric_name.lower()}_{dataset_name}_group_vs_rest.csv"))
        pairwise.to_csv(os.path.join(bias_metrics_folder, f"{metric_name.lower()}_{dataset_name}_pairwise.csv"), index=False)
        with open(os.path.join(bias_metrics_folder, f"{metric_name.lower()}_{dataset_name}_maxmin.txt"), "w") as f:
            f.write(str(max_min))

print(" Extended Bias Metrics Computed & Saved!")