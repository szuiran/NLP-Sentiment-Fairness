# -*- coding: utf-8 -*-
"""customdataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JBED-Ok3yxwVuJblDDygIh1xOrNjpsuB
"""

from google.colab import drive
drive.mount('/content/drive')
import os

# ============================================
# Section 1: Load Trained Models and Tokenizer
# ============================================
# Define model paths (adjust these if necessary)
roberta_model_path = "/content/drive/MyDrive/trained_models/roberta_sst2"
mentalbert_model_path = "/content/drive/MyDrive/models/mentalbert_sst2"

print("RoBERTa model exists:", os.path.exists(roberta_model_path))
print("MentalBERT model exists:", os.path.exists(mentalbert_model_path))

from transformers import AutoModelForSequenceClassification, AutoTokenizer

# Load models from Google Drive
roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_model_path)
mentalbert_model = AutoModelForSequenceClassification.from_pretrained(mentalbert_model_path)

print("✅ Models successfully loaded from Google Drive!")

# Load tokenizer (using RoBERTa's tokenizer for consistency)
tokenizer = AutoTokenizer.from_pretrained(roberta_model_path)

# ============================================
# Section 3: Create Custom Datasets (For Demo Purposes)
# ============================================
import pandas as pd

# Custom Sentences for Gender (without race)
custom_gender_data = [
    {"text": "I feel very sad and hopeless.", "gender": "Female"},
    {"text": "This is the worst experience I've ever had.", "gender": "Male"},
    {"text": "I'm struggling with my mental health lately.", "gender": "Female"},
    {"text": "Life is feeling really overwhelming right now.", "gender": "Male"},
    {"text": "The food at this restaurant was amazing!", "gender": "Female"},
    {"text": "The new company policy is terrible.", "gender": "Male"},
    {"text": "She was so happy to see her friends again.", "gender": "Non-binary"},
    {"text": "The product is a total scam.", "gender": "Female"},
    {"text": "I absolutely loved this movie!", "gender": "Male"},
    {"text": "This is the best day of my life!", "gender": "Female"}
]
df_custom_gender = pd.DataFrame(custom_gender_data)

# Custom Sentences for Race (without gender)
custom_race_data = [
    {"text": "I feel very sad and hopeless.", "race": "Black"},
    {"text": "This is the worst experience I've ever had.", "race": "White"},
    {"text": "I'm struggling with my mental health lately.", "race": "Hispanic"},
    {"text": "Life is feeling really overwhelming right now.", "race": "Asian"},
    {"text": "The food at this restaurant was amazing!", "race": "White"},
    {"text": "The new company policy is terrible.", "race": "Black"},
    {"text": "She was so happy to see her friends again.", "race": "Hispanic"},
    {"text": "The product is a total scam.", "race": "Asian"},
    {"text": "I absolutely loved this movie!", "race": "White"},
    {"text": "This is the best day of my life!", "race": "Black"}
]
df_custom_race = pd.DataFrame(custom_race_data)

# ============================================
# Section 4: Tokenize Custom Datasets
# ============================================
def tokenize_sentences(df, tokenizer, max_length=128):
    """Tokenizes the 'text' column of a DataFrame using the provided tokenizer."""
    return tokenizer(
        df['text'].tolist(),
        padding=True,
        truncation=True,
        max_length=max_length,
        return_tensors="pt"
    )

inputs_custom_gender = tokenize_sentences(df_custom_gender, tokenizer)
inputs_custom_race = tokenize_sentences(df_custom_race, tokenizer)

print("✅ Custom dataset tokenization complete!")

# ============================================
# Section 5: Predict Sentiments on Custom Datasets
# ============================================
import torch

# Set device (preferably GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
roberta_model.to(device)
mentalbert_model.to(device)

def predict_sentiments(model, inputs):
    """Runs inference using the model on the given inputs."""
    inputs = {k: v.to(device) for k, v in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs)
    return torch.argmax(outputs.logits, dim=1).cpu().numpy()

# Predict for custom gender and race datasets
df_custom_gender["roberta_pred"] = predict_sentiments(roberta_model, inputs_custom_gender)
df_custom_gender["mentalbert_pred"] = predict_sentiments(mentalbert_model, inputs_custom_gender)
df_custom_race["roberta_pred"] = predict_sentiments(roberta_model, inputs_custom_race)
df_custom_race["mentalbert_pred"] = predict_sentiments(mentalbert_model, inputs_custom_race)

# Map numeric predictions to labels
sentiment_map = {0: "Negative", 1: "Positive"}
df_custom_gender.replace({"roberta_pred": sentiment_map, "mentalbert_pred": sentiment_map}, inplace=True)
df_custom_race.replace({"roberta_pred": sentiment_map, "mentalbert_pred": sentiment_map}, inplace=True)

print("✅ Custom sentiment predictions completed!")
print("\nCustom Gender-Based Predictions:\n", df_custom_gender)
print("\nCustom Race-Based Predictions:\n", df_custom_race)

# Save custom predictions (optional)
df_custom_gender.to_csv("custom_gender_predictions.csv", index=False)
df_custom_race.to_csv("custom_race_predictions.csv", index=False)
print("✅ Custom predictions saved as CSV files!")